{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'Alley', 'PoolQC', 'Fence', 'MiscFeature' were dropped out since they contained more than 80% null values. Rest of the columns, if of numeric type were filled with mean of the respective column else null values were replaced with mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree termination conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three conditions were used to decide upon when to terminate the tree:\n",
    "    1. If a maximum predefined depth had been reached\n",
    "    2. If the number of samples left were less than a prespecified threshold limit\n",
    "    3. If after splitting along the best found value, one of the two split turns out to be empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical to numerical conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the following attributes had a hierarchial relation among them, hence they were suitably converted to numerical type. However, the mean square error of the predictions improved only by a small margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data type | Metric used for determining split | Mean absolute error | Mean squared error | R2 score |\n",
    "|-----------|---------------|---------------------|--------------------|----------|\n",
    "|converted categorical hierarchial to numerical | MSE | 23999.73 | 1265841364.03 | 0.76 |\n",
    "|left categorical hierarchial intact | MSE | 24590.42 | 1324704484.92 | 0.74 |\n",
    "|left categorical hierarchial intact | MAE | 24373.75 | 1367824704.77 | 0.74 |\n",
    "|converted categorical hierarchial to numerical | MAE | 24954.17 | 1412145253.86 | 0.73 |\n",
    "|converted categorical hierarchial to numerical, kept used column | MSE | 24704.59 | 1319736600.78 | 0.75 |\n",
    "|converted categorical hierarchial to numerical, kept used column | MAE | 23747.55 | 1176833682.77 | 0.77 |\n",
    "|Predicting always mean | - | 54656.09 | 5322462690.05 | -0.0071 |\n",
    "|Predicting always median | - | 51893.63 | 5447828300.60 | -0.030 |\n",
    "|Sklearn's Dtree regressor | MSE | 27144.21 | 1396748683.13 | 0.73 |\n",
    "|Sklearn's Dtree regressor | MAE | 27959.46 | 1785757014.06 | 0.66 |\n",
    "|Sklearn's Dtree regressor | Friedman-MSE | 26593.20 | 1356746873.59 | 0.74 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265841364.038237\n",
      "23999.733693732094\n",
      "0.7604752954801323\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "class node:\n",
    "    def __init__(self, l, r, attr, val):  ##converted categorical hierarchial to numerical and with MSE meteric\n",
    "        self.left = l\n",
    "        self.right = r\n",
    "        self.attribute = attr\n",
    "        self.value = val\n",
    "        self.answer = 0\n",
    "\n",
    "class DecisionTree1:\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "\n",
    "    def build_tree(self, x_f, current_depth, maximum_depth=20, threshold_samples=20):\n",
    "        # print(\"buildtree\")\n",
    "        col_list = list(x_f.columns)\n",
    "        col_list.remove('SalePrice')\n",
    "#         print(\"depth = \"+str(current_depth))\n",
    "        # print(\" got \"+str(len(x_f))+\" rows\", end = ' ')\n",
    "        # print(\" got \"+str(len(col_list))+\" columns\")\n",
    "        tree_node = node(None, None, None, None)\n",
    "        if current_depth == maximum_depth or len(x_f) < threshold_samples:\n",
    "            tree_node.answer = x_f['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        best_attr = []\n",
    "        ser = x_f.dtypes\n",
    "        # print(\"series \",ser)\n",
    "        for attr in col_list:\n",
    "            # print(\"attribute \",attr, end=' ')\n",
    "            if ser[attr] == object:\n",
    "                # print(\"object\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                for split_val in attr_value_list:\n",
    "                    less_frame = x_f[x_f[attr] == split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.square(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] != split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.square(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]                 \n",
    "            else:\n",
    "                # print(\"numerical\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                attr_value_list.sort()\n",
    "                split_list = [((attr_value_list[iv] + attr_value_list[iv+1])/2) for iv in range(len(attr_value_list)-1)]\n",
    "                # print(split_list)\n",
    "                for split_val in split_list:\n",
    "                    less_frame = x_f[x_f[attr] <= split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.square(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] > split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.square(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]    \n",
    "    \n",
    "        tree_node.value = best_attr[1]\n",
    "        tree_node.attribute = best_attr[0]\n",
    "        # print(\"splitting on \"+tree_node.attribute+\" at value \"+str(tree_node.value))\n",
    "        if isinstance(tree_node.value, str):\n",
    "            left_x = x_f[x_f[tree_node.attribute] == tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] != tree_node.value].copy()\n",
    "        else:\n",
    "            left_x = x_f[x_f[tree_node.attribute] <= tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] > tree_node.value].copy()\n",
    "        if(len(left_x)==0):\n",
    "            tree_node.answer = right_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        if(len(right_x)==0):\n",
    "            tree_node.answer = left_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        left_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        right_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        tree_node.left = self.build_tree(left_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        tree_node.right = self.build_tree(right_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        return tree_node\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "        convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "                   'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "                   'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "                   'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "                   'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "                   'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "                   'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "                   'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "                   'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "        for attribute in df.columns:\n",
    "            if attribute in convert_to_num.keys():\n",
    "                df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df\n",
    "\n",
    "    def train(self, train_dataframe_path):\n",
    "        train_df = pd.read_csv(train_dataframe_path, index_col=\"Id\")\n",
    "        train_df = self.preprocessing(train_df)\n",
    "        self.root_node = self.build_tree(train_df, 1)\n",
    "\n",
    "    def predict(self, test_dataframe_path):\n",
    "        test_df = pd.read_csv(test_dataframe_path, index_col=\"Id\")\n",
    "        test_df = self.preprocessing(test_df)\n",
    "        pred_list = []\n",
    "        ser = test_df.dtypes\n",
    "        for test_index in range(len(test_df)):\n",
    "            current_node = self.root_node;\n",
    "            while current_node.left != None and current_node.right != None:\n",
    "                if ser[current_node.attribute] == object:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] == current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "                else:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] <= current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "            pred_list.append(current_node.answer)\n",
    "        return pred_list\n",
    "\n",
    " \n",
    "dtree_regressor = DecisionTree1()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324704484.9292908\n",
      "24590.42097664111\n",
      "0.749337113367353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    " #left categorical hierarchial intact,with MSE meteric\n",
    "\n",
    "class DecisionTree2:\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "\n",
    "    def build_tree(self, x_f, current_depth, maximum_depth=20, threshold_samples=20):\n",
    "        # print(\"buildtree\")\n",
    "        col_list = list(x_f.columns)\n",
    "        col_list.remove('SalePrice')\n",
    "#         print(\"depth = \"+str(current_depth))\n",
    "        # print(\" got \"+str(len(x_f))+\" rows\", end = ' ')\n",
    "        # print(\" got \"+str(len(col_list))+\" columns\")\n",
    "        tree_node = node(None, None, None, None)\n",
    "        if current_depth == maximum_depth or len(x_f) < threshold_samples:\n",
    "            tree_node.answer = x_f['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        best_attr = []\n",
    "        ser = x_f.dtypes\n",
    "        # print(\"series \",ser)\n",
    "        for attr in col_list:\n",
    "            # print(\"attribute \",attr, end=' ')\n",
    "            if ser[attr] == object:\n",
    "                # print(\"object\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                for split_val in attr_value_list:\n",
    "                    less_frame = x_f[x_f[attr] == split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.square(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] != split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.square(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]                 \n",
    "            else:\n",
    "                # print(\"numerical\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                attr_value_list.sort()\n",
    "                split_list = [((attr_value_list[iv] + attr_value_list[iv+1])/2) for iv in range(len(attr_value_list)-1)]\n",
    "                # print(split_list)\n",
    "                for split_val in split_list:\n",
    "                    less_frame = x_f[x_f[attr] <= split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.square(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] > split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.square(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]    \n",
    "    \n",
    "        tree_node.value = best_attr[1]\n",
    "        tree_node.attribute = best_attr[0]\n",
    "        # print(\"splitting on \"+tree_node.attribute+\" at value \"+str(tree_node.value))\n",
    "        if isinstance(tree_node.value, str):\n",
    "            left_x = x_f[x_f[tree_node.attribute] == tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] != tree_node.value].copy()\n",
    "        else:\n",
    "            left_x = x_f[x_f[tree_node.attribute] <= tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] > tree_node.value].copy()\n",
    "        if(len(left_x)==0):\n",
    "            tree_node.answer = right_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        if(len(right_x)==0):\n",
    "            tree_node.answer = left_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        left_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        right_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        tree_node.left = self.build_tree(left_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        tree_node.right = self.build_tree(right_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        return tree_node\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "#         convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "#                    'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "#                    'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "#                    'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "#                    'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "#                    'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "#                    'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "#                    'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "#                    'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "#                    'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "#                    'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "#                    'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "#                    'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "#         for attribute in df.columns:\n",
    "#             if attribute in convert_to_num.keys():\n",
    "#                 df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df\n",
    "\n",
    "    def train(self, train_dataframe_path):\n",
    "        train_df = pd.read_csv(train_dataframe_path, index_col=\"Id\")\n",
    "        train_df = self.preprocessing(train_df)\n",
    "        self.root_node = self.build_tree(train_df, 1)\n",
    "\n",
    "    def predict(self, test_dataframe_path):\n",
    "        test_df = pd.read_csv(test_dataframe_path, index_col=\"Id\")\n",
    "        test_df = self.preprocessing(test_df)\n",
    "        pred_list = []\n",
    "        ser = test_df.dtypes\n",
    "        for test_index in range(len(test_df)):\n",
    "            current_node = self.root_node;\n",
    "            while current_node.left != None and current_node.right != None:\n",
    "                if ser[current_node.attribute] == object:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] == current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "                else:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] <= current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "            pred_list.append(current_node.answer)\n",
    "        return pred_list\n",
    "\n",
    "\n",
    "dtree_regressor = DecisionTree2()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367824704.772412\n",
      "24373.755359157414\n",
      "0.7411778303717284\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    " #left categorical hierarchial intact,with MAE meteric\n",
    "\n",
    "class DecisionTree3:\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "\n",
    "    def build_tree(self, x_f, current_depth, maximum_depth=20, threshold_samples=20):\n",
    "        # print(\"buildtree\")\n",
    "        col_list = list(x_f.columns)\n",
    "        col_list.remove('SalePrice')\n",
    "#         print(\"depth = \"+str(current_depth))\n",
    "        # print(\" got \"+str(len(x_f))+\" rows\", end = ' ')\n",
    "        # print(\" got \"+str(len(col_list))+\" columns\")\n",
    "        tree_node = node(None, None, None, None)\n",
    "        if current_depth == maximum_depth or len(x_f) < threshold_samples:\n",
    "            tree_node.answer = x_f['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        best_attr = []\n",
    "        ser = x_f.dtypes\n",
    "        # print(\"series \",ser)\n",
    "        for attr in col_list:\n",
    "            # print(\"attribute \",attr, end=' ')\n",
    "            if ser[attr] == object:\n",
    "                # print(\"object\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                for split_val in attr_value_list:\n",
    "                    less_frame = x_f[x_f[attr] == split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.absolute(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] != split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.absolute(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]                 \n",
    "            else:\n",
    "                # print(\"numerical\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                attr_value_list.sort()\n",
    "                split_list = [((attr_value_list[iv] + attr_value_list[iv+1])/2) for iv in range(len(attr_value_list)-1)]\n",
    "                # print(split_list)\n",
    "                for split_val in split_list:\n",
    "                    less_frame = x_f[x_f[attr] <= split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.absolute(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] > split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.absolute(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]    \n",
    "    \n",
    "        tree_node.value = best_attr[1]\n",
    "        tree_node.attribute = best_attr[0]\n",
    "        # print(\"splitting on \"+tree_node.attribute+\" at value \"+str(tree_node.value))\n",
    "        if isinstance(tree_node.value, str):\n",
    "            left_x = x_f[x_f[tree_node.attribute] == tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] != tree_node.value].copy()\n",
    "        else:\n",
    "            left_x = x_f[x_f[tree_node.attribute] <= tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] > tree_node.value].copy()\n",
    "        if(len(left_x)==0):\n",
    "            tree_node.answer = right_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        if(len(right_x)==0):\n",
    "            tree_node.answer = left_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        left_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        right_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        tree_node.left = self.build_tree(left_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        tree_node.right = self.build_tree(right_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        return tree_node\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "#         convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "#                    'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "#                    'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "#                    'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "#                    'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "#                    'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "#                    'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "#                    'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "#                    'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "#                    'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "#                    'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "#                    'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "#                    'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "#         for attribute in df.columns:\n",
    "#             if attribute in convert_to_num.keys():\n",
    "#                 df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df\n",
    "\n",
    "    def train(self, train_dataframe_path):\n",
    "        train_df = pd.read_csv(train_dataframe_path, index_col=\"Id\")\n",
    "        train_df = self.preprocessing(train_df)\n",
    "        self.root_node = self.build_tree(train_df, 1)\n",
    "\n",
    "    def predict(self, test_dataframe_path):\n",
    "        test_df = pd.read_csv(test_dataframe_path, index_col=\"Id\")\n",
    "        test_df = self.preprocessing(test_df)\n",
    "        pred_list = []\n",
    "        ser = test_df.dtypes\n",
    "        for test_index in range(len(test_df)):\n",
    "            current_node = self.root_node;\n",
    "            while current_node.left != None and current_node.right != None:\n",
    "                if ser[current_node.attribute] == object:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] == current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "                else:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] <= current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "            pred_list.append(current_node.answer)\n",
    "        return pred_list\n",
    "\n",
    "\n",
    "dtree_regressor = DecisionTree3()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412145253.8675234\n",
      "24954.179043743232\n",
      "0.7327914189873678\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "#converted categorical hierarchial to numerical, with MAE meteric\n",
    "\n",
    "class DecisionTree4:\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "\n",
    "    def build_tree(self, x_f, current_depth, maximum_depth=20, threshold_samples=20):\n",
    "        # print(\"buildtree\")\n",
    "        col_list = list(x_f.columns)\n",
    "        col_list.remove('SalePrice')\n",
    "#         print(\"depth = \"+str(current_depth))\n",
    "        # print(\" got \"+str(len(x_f))+\" rows\", end = ' ')\n",
    "        # print(\" got \"+str(len(col_list))+\" columns\")\n",
    "        tree_node = node(None, None, None, None)\n",
    "        if current_depth == maximum_depth or len(x_f) < threshold_samples:\n",
    "            tree_node.answer = x_f['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        best_attr = []\n",
    "        ser = x_f.dtypes\n",
    "        # print(\"series \",ser)\n",
    "        for attr in col_list:\n",
    "            # print(\"attribute \",attr, end=' ')\n",
    "            if ser[attr] == object:\n",
    "                # print(\"object\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                for split_val in attr_value_list:\n",
    "                    less_frame = x_f[x_f[attr] == split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.absolute(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] != split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.absolute(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]                 \n",
    "            else:\n",
    "                # print(\"numerical\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                attr_value_list.sort()\n",
    "                split_list = [((attr_value_list[iv] + attr_value_list[iv+1])/2) for iv in range(len(attr_value_list)-1)]\n",
    "                # print(split_list)\n",
    "                for split_val in split_list:\n",
    "                    less_frame = x_f[x_f[attr] <= split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.absolute(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] > split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.absolute(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]    \n",
    "    \n",
    "        tree_node.value = best_attr[1]\n",
    "        tree_node.attribute = best_attr[0]\n",
    "        # print(\"splitting on \"+tree_node.attribute+\" at value \"+str(tree_node.value))\n",
    "        if isinstance(tree_node.value, str):\n",
    "            left_x = x_f[x_f[tree_node.attribute] == tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] != tree_node.value].copy()\n",
    "        else:\n",
    "            left_x = x_f[x_f[tree_node.attribute] <= tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] > tree_node.value].copy()\n",
    "        if(len(left_x)==0):\n",
    "            tree_node.answer = right_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        if(len(right_x)==0):\n",
    "            tree_node.answer = left_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        left_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        right_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        tree_node.left = self.build_tree(left_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        tree_node.right = self.build_tree(right_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        return tree_node\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "        convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "                   'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "                   'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "                   'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "                   'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "                   'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "                   'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "                   'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "                   'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "        for attribute in df.columns:\n",
    "            if attribute in convert_to_num.keys():\n",
    "                df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df\n",
    "\n",
    "    def train(self, train_dataframe_path):\n",
    "        train_df = pd.read_csv(train_dataframe_path, index_col=\"Id\")\n",
    "        train_df = self.preprocessing(train_df)\n",
    "        self.root_node = self.build_tree(train_df, 1)\n",
    "\n",
    "    def predict(self, test_dataframe_path):\n",
    "        test_df = pd.read_csv(test_dataframe_path, index_col=\"Id\")\n",
    "        test_df = self.preprocessing(test_df)\n",
    "        pred_list = []\n",
    "        ser = test_df.dtypes\n",
    "        for test_index in range(len(test_df)):\n",
    "            current_node = self.root_node;\n",
    "            while current_node.left != None and current_node.right != None:\n",
    "                if ser[current_node.attribute] == object:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] == current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "                else:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] <= current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "            pred_list.append(current_node.answer)\n",
    "        return pred_list\n",
    "\n",
    "\n",
    "dtree_regressor = DecisionTree4()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319736600.7859044\n",
      "24704.595260616108\n",
      "0.7502771450453647\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "#converted categorical hierarchial to numerical, with MSE meteric, not dropping used column\n",
    "\n",
    "class DecisionTree5:\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "\n",
    "    def build_tree(self, x_f, current_depth, maximum_depth=20, threshold_samples=20):\n",
    "        # print(\"buildtree\")\n",
    "        col_list = list(x_f.columns)\n",
    "        col_list.remove('SalePrice')\n",
    "#         print(\"depth = \"+str(current_depth))\n",
    "        # print(\" got \"+str(len(x_f))+\" rows\", end = ' ')\n",
    "        # print(\" got \"+str(len(col_list))+\" columns\")\n",
    "        tree_node = node(None, None, None, None)\n",
    "        if current_depth == maximum_depth or len(x_f) < threshold_samples:\n",
    "            tree_node.answer = x_f['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        best_attr = []\n",
    "        ser = x_f.dtypes\n",
    "        # print(\"series \",ser)\n",
    "        for attr in col_list:\n",
    "            # print(\"attribute \",attr, end=' ')\n",
    "            if ser[attr] == object:\n",
    "                # print(\"object\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                for split_val in attr_value_list:\n",
    "                    less_frame = x_f[x_f[attr] == split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.square(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] != split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.square(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]                 \n",
    "            else:\n",
    "                # print(\"numerical\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                attr_value_list.sort()\n",
    "                split_list = [((attr_value_list[iv] + attr_value_list[iv+1])/2) for iv in range(len(attr_value_list)-1)]\n",
    "                # print(split_list)\n",
    "                for split_val in split_list:\n",
    "                    less_frame = x_f[x_f[attr] <= split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.square(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] > split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.square(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]    \n",
    "    \n",
    "        tree_node.value = best_attr[1]\n",
    "        tree_node.attribute = best_attr[0]\n",
    "        # print(\"splitting on \"+tree_node.attribute+\" at value \"+str(tree_node.value))\n",
    "        if isinstance(tree_node.value, str):\n",
    "            left_x = x_f[x_f[tree_node.attribute] == tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] != tree_node.value].copy()\n",
    "        else:\n",
    "            left_x = x_f[x_f[tree_node.attribute] <= tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] > tree_node.value].copy()\n",
    "        if(len(left_x)==0):\n",
    "            tree_node.answer = right_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        if(len(right_x)==0):\n",
    "            tree_node.answer = left_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "#         left_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "#         right_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        tree_node.left = self.build_tree(left_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        tree_node.right = self.build_tree(right_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        return tree_node\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "        convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "                   'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "                   'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "                   'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "                   'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "                   'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "                   'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "                   'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "                   'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "        for attribute in df.columns:\n",
    "            if attribute in convert_to_num.keys():\n",
    "                df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df\n",
    "\n",
    "    def train(self, train_dataframe_path):\n",
    "        train_df = pd.read_csv(train_dataframe_path, index_col=\"Id\")\n",
    "        train_df = self.preprocessing(train_df)\n",
    "        self.root_node = self.build_tree(train_df, 1)\n",
    "\n",
    "    def predict(self, test_dataframe_path):\n",
    "        test_df = pd.read_csv(test_dataframe_path, index_col=\"Id\")\n",
    "        test_df = self.preprocessing(test_df)\n",
    "        pred_list = []\n",
    "        ser = test_df.dtypes\n",
    "        for test_index in range(len(test_df)):\n",
    "            current_node = self.root_node;\n",
    "            while current_node.left != None and current_node.right != None:\n",
    "                if ser[current_node.attribute] == object:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] == current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "                else:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] <= current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "            pred_list.append(current_node.answer)\n",
    "        return pred_list\n",
    "\n",
    "\n",
    "dtree_regressor = DecisionTree5()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176833682.7755482\n",
      "23747.555894256842\n",
      "0.7773174837354058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "#converted categorical hierarchial to numerical, with MAE metric, not dropping used column\n",
    "\n",
    "class DecisionTree6:\n",
    "    def __init__(self):\n",
    "        self.root_node = None\n",
    "\n",
    "    def build_tree(self, x_f, current_depth, maximum_depth=20, threshold_samples=20):\n",
    "        # print(\"buildtree\")\n",
    "        col_list = list(x_f.columns)\n",
    "        col_list.remove('SalePrice')\n",
    "#         print(\"depth = \"+str(current_depth))\n",
    "        # print(\" got \"+str(len(x_f))+\" rows\", end = ' ')\n",
    "        # print(\" got \"+str(len(col_list))+\" columns\")\n",
    "        tree_node = node(None, None, None, None)\n",
    "        if current_depth == maximum_depth or len(x_f) < threshold_samples:\n",
    "            tree_node.answer = x_f['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        best_attr = []\n",
    "        ser = x_f.dtypes\n",
    "        # print(\"series \",ser)\n",
    "        for attr in col_list:\n",
    "            # print(\"attribute \",attr, end=' ')\n",
    "            if ser[attr] == object:\n",
    "                # print(\"object\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                for split_val in attr_value_list:\n",
    "                    less_frame = x_f[x_f[attr] == split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.absolute(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] != split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.absolute(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]                 \n",
    "            else:\n",
    "                # print(\"numerical\")\n",
    "                attr_values_set = np.unique(x_f[attr])\n",
    "                attr_value_list = list(attr_values_set)\n",
    "                attr_value_list.sort()\n",
    "                split_list = [((attr_value_list[iv] + attr_value_list[iv+1])/2) for iv in range(len(attr_value_list)-1)]\n",
    "                # print(split_list)\n",
    "                for split_val in split_list:\n",
    "                    less_frame = x_f[x_f[attr] <= split_val].copy()\n",
    "                    left_error = 0\n",
    "                    if len(less_frame):\n",
    "                        less_array = less_frame['SalePrice'].to_numpy()\n",
    "                        less_array = less_array.astype('float64')\n",
    "                        less_array -= less_array.mean()\n",
    "                        less_array = np.absolute(less_array)\n",
    "                        left_error = less_array.sum()*(len(less_array)/len(x_f))\n",
    "                    more_frame = x_f[x_f[attr] > split_val].copy()\n",
    "                    right_error = 0\n",
    "                    if len(more_frame):\n",
    "                        more_array = more_frame['SalePrice'].to_numpy()\n",
    "                        more_array = more_array.astype('float64')\n",
    "                        more_array -= more_array.mean()\n",
    "                        more_array = np.absolute(more_array)\n",
    "                        right_error = more_array.sum()*(len(more_array)/len(x_f))\n",
    "                    mean_sq_error = left_error + right_error\n",
    "                    if len(best_attr):\n",
    "                        if best_attr[2] > mean_sq_error:\n",
    "                            best_attr = [attr, split_val, mean_sq_error]\n",
    "                    else:\n",
    "                        best_attr = [attr, split_val, mean_sq_error]    \n",
    "    \n",
    "        tree_node.value = best_attr[1]\n",
    "        tree_node.attribute = best_attr[0]\n",
    "        # print(\"splitting on \"+tree_node.attribute+\" at value \"+str(tree_node.value))\n",
    "        if isinstance(tree_node.value, str):\n",
    "            left_x = x_f[x_f[tree_node.attribute] == tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] != tree_node.value].copy()\n",
    "        else:\n",
    "            left_x = x_f[x_f[tree_node.attribute] <= tree_node.value].copy()\n",
    "            right_x = x_f[x_f[tree_node.attribute] > tree_node.value].copy()\n",
    "        if(len(left_x)==0):\n",
    "            tree_node.answer = right_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "        if(len(right_x)==0):\n",
    "            tree_node.answer = left_x['SalePrice'].mean()\n",
    "            return tree_node\n",
    "#         left_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "#         right_x.drop(columns=[best_attr[0]], inplace=True)\n",
    "        tree_node.left = self.build_tree(left_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        tree_node.right = self.build_tree(right_x, current_depth+1, maximum_depth, threshold_samples)\n",
    "        return tree_node\n",
    "\n",
    "    def preprocessing(self, df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "        convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "                   'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "                   'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "                   'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "                   'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "                   'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "                   'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "                   'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "                   'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "                   'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "                   'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "                   'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "                   'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "        for attribute in df.columns:\n",
    "            if attribute in convert_to_num.keys():\n",
    "                df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df\n",
    "\n",
    "    def train(self, train_dataframe_path):\n",
    "        train_df = pd.read_csv(train_dataframe_path, index_col=\"Id\")\n",
    "        train_df = self.preprocessing(train_df)\n",
    "        self.root_node = self.build_tree(train_df, 1)\n",
    "\n",
    "    def predict(self, test_dataframe_path):\n",
    "        test_df = pd.read_csv(test_dataframe_path, index_col=\"Id\")\n",
    "        test_df = self.preprocessing(test_df)\n",
    "        pred_list = []\n",
    "        ser = test_df.dtypes\n",
    "        for test_index in range(len(test_df)):\n",
    "            current_node = self.root_node;\n",
    "            while current_node.left != None and current_node.right != None:\n",
    "                if ser[current_node.attribute] == object:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] == current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "                else:\n",
    "                    if test_df.iloc[test_index][current_node.attribute] <= current_node.value:\n",
    "                        current_node = current_node.left\n",
    "                    else:\n",
    "                        current_node = current_node.right\n",
    "            pred_list.append(current_node.answer)\n",
    "        return pred_list\n",
    "\n",
    "\n",
    "dtree_regressor = DecisionTree6()\n",
    "dtree_regressor.train('./Datasets/q3/train.csv')\n",
    "predictions = dtree_regressor.predict('./Datasets/q3/test.csv')\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "        df.fillna(value=\"others\", inplace=True)\n",
    "        df.drop(columns=['Alley', 'PoolQC', 'Fence', 'MiscFeature'], inplace=True)\n",
    "#         convert_to_num = {'LotShape':{'Reg':4, 'IR1':3, 'IR2':2, 'IR3':1}, \n",
    "#                    'LandContour':{'Lvl':4, 'Bnk':3, 'HLS':2, 'Low':1},\n",
    "#                    'Utilities':{'AllPub':4, 'NoSewr':3, 'NoSeWa':2, 'ELO':1},\n",
    "#                    'LandSlope':{'Gtl':3, 'Mod':2, 'Sev':1},\n",
    "#                    'ExterQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'ExterCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'BsmtQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "#                    'BsmtCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0},\n",
    "#                    'BsmtExposure':{'Gd':5, 'Av':4, 'Mn':3, 'No':2, 'others':1},\n",
    "#                    'BsmtFinType1':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "#                    'BsmtFinType2':{'GLQ':7, 'ALQ':6, 'BLQ':5, 'Rec':4, 'LwQ':3, 'Unf':2, 'others':1},\n",
    "#                    'HeatingQC':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1},\n",
    "#                    'KitchenQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1}, \n",
    "#                    'Functional':{'Typ':8, 'Min1':7, 'Min2':6, 'Mod':5, 'Maj1':4, 'Maj2':3, 'Sev':2, 'Sal':1}, \n",
    "#                    'FireplaceQu':{'Ex':6, 'Gd':5, 'TA':4, 'Masonry':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'GarageFinish':{'Fin':4, 'RFn':3, 'Unf':2, 'others':1}, \n",
    "#                    'GarageQual':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'GarageCond':{'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, 'others':0}, \n",
    "#                    'PavedDrive':{'Y':3, 'P':2, 'N':1}}\n",
    "#         for attribute in df.columns:\n",
    "#             if attribute in convert_to_num.keys():\n",
    "#                 df[attribute] = df[attribute].map(convert_to_num[attribute])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396748683.1326087\n",
      "27144.215217391305\n",
      "0.7357047848803377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# le = LabelEncoder()\n",
    "train_df = pd.read_csv('./Datasets/q3/train.csv', index_col=\"Id\")\n",
    "train_df = preprocessing(train_df)\n",
    "train_res = train_df['SalePrice']\n",
    "train_df.drop(columns=['SalePrice'], inplace=True)\n",
    "test_df = pd.read_csv('./Datasets/q3/test.csv', index_col=\"Id\")\n",
    "test_df = preprocessing(test_df)\n",
    "ser = test_df.dtypes\n",
    "for attr in test_df.columns:\n",
    "    if ser[attr] == object:\n",
    "        train_df[attr] = le.fit_transform(train_df[attr])\n",
    "        test_df[attr] = le.fit_transform(test_df[attr])\n",
    "\n",
    "# categorical_feature_mask = train_df.dtypes==object\n",
    "# onehotencoder = OneHotEncoder() \n",
    "# train_data = onehotencoder.fit_transform(train_df).toarray()\n",
    "# print(train_data.shape)\n",
    "# test_data = onehotencoder.transform(test_df).toarray()\n",
    "# print(test_data.shape)\n",
    "clf = DecisionTreeRegressor(criterion='mse')\n",
    "clf.fit(train_df, train_res)\n",
    "predictions = clf.predict(test_df)\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785757014.0630436\n",
      "27959.467391304348\n",
      "0.662095951918339\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(criterion='mae')\n",
    "clf.fit(train_df, train_res)\n",
    "predictions = clf.predict(test_df)\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356746873.597826\n",
      "26593.206521739132\n",
      "0.7432739968537185\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(criterion='friedman_mse')\n",
    "clf.fit(train_df, train_res)\n",
    "predictions = clf.predict(test_df)\n",
    "test_labels = list()\n",
    "with open(\"./Datasets/q3/test_labels.csv\") as f:\n",
    "  for line in f:\n",
    "    test_labels.append(float(line.split(',')[1]))\n",
    "print (mean_squared_error(test_labels, predictions))\n",
    "print (mean_absolute_error(test_labels, predictions))\n",
    "print (r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5322462690.052036\n",
      "54656.09460869566\n",
      "-0.007125647313121597\n",
      "5447828300.608696\n",
      "51893.639130434785\n",
      "-0.030847546184985086\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./Datasets/q3/train.csv', index_col=\"Id\")\n",
    "always_mean = [train_df['SalePrice'].mean()]*len(test_df)\n",
    "always_median = [train_df['SalePrice'].median()]*len(test_df)\n",
    "print (mean_squared_error(test_labels, always_mean))\n",
    "print (mean_absolute_error(test_labels, always_mean))\n",
    "print (r2_score(test_labels, always_mean))\n",
    "print (mean_squared_error(test_labels, always_median))\n",
    "print (mean_absolute_error(test_labels, always_median))\n",
    "print (r2_score(test_labels, always_median))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
